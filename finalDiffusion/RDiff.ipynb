{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion model for clutter denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "#from models.unet import *\n",
    "from models.DUnet import *\n",
    "import torch.optim as optim\n",
    "#from utils.trainer import *\n",
    "from utils.Dtrainer import *\n",
    "from torch.optim import Adam\n",
    "from utils.plotters import *\n",
    "from utils.inference import *\n",
    "#from models.diffusion import *\n",
    "from models.DDiffusion import *\n",
    "from dataset.radardata import *\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialiaze W&B + config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'comp1-dualbranch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mari-granevich\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hawk/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/wandb/run-20250422_153507-9urzcl7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ari-granevich/New-Radar-diffusion2/runs/9urzcl7h' target=\"_blank\">comp1-dualbranch</a></strong> to <a href='https://wandb.ai/ari-granevich/New-Radar-diffusion2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ari-granevich/New-Radar-diffusion2' target=\"_blank\">https://wandb.ai/ari-granevich/New-Radar-diffusion2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ari-granevich/New-Radar-diffusion2/runs/9urzcl7h' target=\"_blank\">https://wandb.ai/ari-granevich/New-Radar-diffusion2/runs/9urzcl7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"New-Radar-diffusion2\",\n",
    "    name=run_name,\n",
    "    notes=\"Regular diffusion. this experiment is our benchmark - we check if changes are performing better or worse\",\n",
    "    config={\n",
    "        \"beta_end\": 0.02,\n",
    "        \"beta_start\": 1e-4,\n",
    "        \"batch_size\": 8,\n",
    "        \"num_epochs\": 400,\n",
    "        \"noise_steps\": 2000,\n",
    "        \"num_workers\": 4,\n",
    "        \"time_emb_dim\": 256,\n",
    "        \"learning_rate\": 1e-4,        \n",
    "        \"scheduler_type\": \"linear\",\n",
    "    },\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_dataset = torch.load(\"norm_train_dataset_1015.pt\", weights_only=False)\n",
    "norm_val_dataset   = torch.load(\"norm_val_dataset_1015.pt\",   weights_only=False)\n",
    "norm_train_loader = DataLoader(\n",
    "    norm_train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "norm_val_loader = DataLoader(\n",
    "    norm_val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hawk/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400  Train Loss: 0.9695  Val Loss: 0.9484\n",
      "   → Sampled MSE: 1123902592.0000  PSNR: -54.21dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 2/400  Train Loss: 0.9342  Val Loss: 0.9222\n",
      "   → Sampled MSE: 1066264448.0000  PSNR: -53.98dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 3/400  Train Loss: 0.9125  Val Loss: 0.9048\n",
      "   → Sampled MSE: 1039244416.0000  PSNR: -53.87dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 4/400  Train Loss: 0.8993  Val Loss: 0.8951\n",
      "   → Sampled MSE: 1029993152.0000  PSNR: -53.83dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 5/400  Train Loss: 0.8909  Val Loss: 0.8877\n",
      "   → Sampled MSE: 1006057472.0000  PSNR: -53.73dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 6/400  Train Loss: 0.8845  Val Loss: 0.8810\n",
      "   → Sampled MSE: 1002067776.0000  PSNR: -53.71dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 7/400  Train Loss: 0.8800  Val Loss: 0.8779\n",
      "   → Sampled MSE: 992512576.0000  PSNR: -53.67dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 8/400  Train Loss: 0.8762  Val Loss: 0.8738\n",
      "   → Sampled MSE: 978494336.0000  PSNR: -53.61dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 9/400  Train Loss: 0.8728  Val Loss: 0.8707\n",
      "   → Sampled MSE: 967715200.0000  PSNR: -53.56dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 10/400  Train Loss: 0.8697  Val Loss: 0.8684\n",
      "   → Sampled MSE: 962006528.0000  PSNR: -53.54dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 11/400  Train Loss: 0.8671  Val Loss: 0.8651\n",
      "   → Sampled MSE: 970566016.0000  PSNR: -53.58dB\n",
      "Epoch 12/400  Train Loss: 0.8649  Val Loss: 0.8629\n",
      "   → Sampled MSE: 963391360.0000  PSNR: -53.54dB\n",
      "Epoch 13/400  Train Loss: 0.8627  Val Loss: 0.8611\n",
      "   → Sampled MSE: 952315776.0000  PSNR: -53.49dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 14/400  Train Loss: 0.8602  Val Loss: 0.8588\n",
      "   → Sampled MSE: 951869184.0000  PSNR: -53.49dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 15/400  Train Loss: 0.8583  Val Loss: 0.8572\n",
      "   → Sampled MSE: 942156672.0000  PSNR: -53.45dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 16/400  Train Loss: 0.8564  Val Loss: 0.8554\n",
      "   → Sampled MSE: 946448128.0000  PSNR: -53.47dB\n",
      "Epoch 17/400  Train Loss: 0.8546  Val Loss: 0.8539\n",
      "   → Sampled MSE: 936423040.0000  PSNR: -53.42dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 18/400  Train Loss: 0.8532  Val Loss: 0.8532\n",
      "   → Sampled MSE: 946418752.0000  PSNR: -53.47dB\n",
      "Epoch 19/400  Train Loss: 0.8515  Val Loss: 0.8498\n",
      "   → Sampled MSE: 929395136.0000  PSNR: -53.39dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 20/400  Train Loss: 0.8499  Val Loss: 0.8489\n",
      "   → Sampled MSE: 935476224.0000  PSNR: -53.42dB\n",
      "Epoch 21/400  Train Loss: 0.8486  Val Loss: 0.8483\n",
      "   → Sampled MSE: 932235904.0000  PSNR: -53.40dB\n",
      "Epoch 22/400  Train Loss: 0.8472  Val Loss: 0.8464\n",
      "   → Sampled MSE: 924988800.0000  PSNR: -53.37dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 23/400  Train Loss: 0.8458  Val Loss: 0.8455\n",
      "   → Sampled MSE: 926079872.0000  PSNR: -53.37dB\n",
      "Epoch 24/400  Train Loss: 0.8444  Val Loss: 0.8443\n",
      "   → Sampled MSE: 917332096.0000  PSNR: -53.33dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 25/400  Train Loss: 0.8433  Val Loss: 0.8417\n",
      "   → Sampled MSE: 914906624.0000  PSNR: -53.32dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 26/400  Train Loss: 0.8422  Val Loss: 0.8413\n",
      "   → Sampled MSE: 921220416.0000  PSNR: -53.35dB\n",
      "Epoch 27/400  Train Loss: 0.8408  Val Loss: 0.8401\n",
      "   → Sampled MSE: 902711168.0000  PSNR: -53.26dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 28/400  Train Loss: 0.8398  Val Loss: 0.8387\n",
      "   → Sampled MSE: 910954432.0000  PSNR: -53.30dB\n",
      "Epoch 29/400  Train Loss: 0.8388  Val Loss: 0.8375\n",
      "   → Sampled MSE: 909066048.0000  PSNR: -53.29dB\n",
      "Epoch 30/400  Train Loss: 0.8374  Val Loss: 0.8371\n",
      "   → Sampled MSE: 903822272.0000  PSNR: -53.27dB\n",
      "Epoch 31/400  Train Loss: 0.8363  Val Loss: 0.8354\n",
      "   → Sampled MSE: 898024064.0000  PSNR: -53.24dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 32/400  Train Loss: 0.8355  Val Loss: 0.8351\n",
      "   → Sampled MSE: 896040192.0000  PSNR: -53.23dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 33/400  Train Loss: 0.8348  Val Loss: 0.8355\n",
      "   → Sampled MSE: 904337856.0000  PSNR: -53.27dB\n",
      "Epoch 34/400  Train Loss: 0.8337  Val Loss: 0.8334\n",
      "   → Sampled MSE: 903499456.0000  PSNR: -53.26dB\n",
      "Epoch 35/400  Train Loss: 0.8327  Val Loss: 0.8332\n",
      "   → Sampled MSE: 906289216.0000  PSNR: -53.28dB\n",
      "Epoch 36/400  Train Loss: 0.8319  Val Loss: 0.8311\n",
      "   → Sampled MSE: 894667712.0000  PSNR: -53.22dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 37/400  Train Loss: 0.8311  Val Loss: 0.8323\n",
      "   → Sampled MSE: 889057536.0000  PSNR: -53.19dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 38/400  Train Loss: 0.8302  Val Loss: 0.8301\n",
      "   → Sampled MSE: 894518400.0000  PSNR: -53.22dB\n",
      "Epoch 39/400  Train Loss: 0.8294  Val Loss: 0.8297\n",
      "   → Sampled MSE: 889853696.0000  PSNR: -53.20dB\n",
      "Epoch 40/400  Train Loss: 0.8283  Val Loss: 0.8272\n",
      "   → Sampled MSE: 881620800.0000  PSNR: -53.16dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 41/400  Train Loss: 0.8280  Val Loss: 0.8279\n",
      "   → Sampled MSE: 893594624.0000  PSNR: -53.22dB\n",
      "Epoch 42/400  Train Loss: 0.8273  Val Loss: 0.8266\n",
      "   → Sampled MSE: 879539584.0000  PSNR: -53.15dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 43/400  Train Loss: 0.8265  Val Loss: 0.8263\n",
      "   → Sampled MSE: 880746240.0000  PSNR: -53.15dB\n",
      "Epoch 44/400  Train Loss: 0.8255  Val Loss: 0.8249\n",
      "   → Sampled MSE: 877614080.0000  PSNR: -53.14dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 45/400  Train Loss: 0.8248  Val Loss: 0.8245\n",
      "   → Sampled MSE: 875215296.0000  PSNR: -53.13dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 46/400  Train Loss: 0.8249  Val Loss: 0.8243\n",
      "   → Sampled MSE: 874477056.0000  PSNR: -53.12dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 47/400  Train Loss: 0.8235  Val Loss: 0.8254\n",
      "   → Sampled MSE: 870781056.0000  PSNR: -53.10dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 48/400  Train Loss: 0.8230  Val Loss: 0.8233\n",
      "   → Sampled MSE: 881620352.0000  PSNR: -53.16dB\n",
      "Epoch 49/400  Train Loss: 0.8225  Val Loss: 0.8219\n",
      "   → Sampled MSE: 871437248.0000  PSNR: -53.11dB\n",
      "Epoch 50/400  Train Loss: 0.8217  Val Loss: 0.8218\n",
      "   → Sampled MSE: 870937472.0000  PSNR: -53.10dB\n",
      "Epoch 51/400  Train Loss: 0.8215  Val Loss: 0.8212\n",
      "   → Sampled MSE: 871672576.0000  PSNR: -53.11dB\n",
      "Epoch 52/400  Train Loss: 0.8207  Val Loss: 0.8188\n",
      "   → Sampled MSE: 864339264.0000  PSNR: -53.07dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 53/400  Train Loss: 0.8200  Val Loss: 0.8199\n",
      "   → Sampled MSE: 875533184.0000  PSNR: -53.13dB\n",
      "Epoch 54/400  Train Loss: 0.8197  Val Loss: 0.8202\n",
      "   → Sampled MSE: 870307200.0000  PSNR: -53.10dB\n",
      "Epoch 55/400  Train Loss: 0.8191  Val Loss: 0.8191\n",
      "   → Sampled MSE: 869069312.0000  PSNR: -53.10dB\n",
      "Epoch 56/400  Train Loss: 0.8188  Val Loss: 0.8186\n",
      "   → Sampled MSE: 873907456.0000  PSNR: -53.12dB\n",
      "Epoch 57/400  Train Loss: 0.8181  Val Loss: 0.8177\n",
      "   → Sampled MSE: 863268416.0000  PSNR: -53.07dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 58/400  Train Loss: 0.8179  Val Loss: 0.8168\n",
      "   → Sampled MSE: 848866176.0000  PSNR: -52.99dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 59/400  Train Loss: 0.8172  Val Loss: 0.8185\n",
      "   → Sampled MSE: 861356288.0000  PSNR: -53.06dB\n",
      "Epoch 60/400  Train Loss: 0.8168  Val Loss: 0.8165\n",
      "   → Sampled MSE: 851237376.0000  PSNR: -53.01dB\n",
      "Epoch 61/400  Train Loss: 0.8158  Val Loss: 0.8161\n",
      "   → Sampled MSE: 857763584.0000  PSNR: -53.04dB\n",
      "Epoch 62/400  Train Loss: 0.8154  Val Loss: 0.8158\n",
      "   → Sampled MSE: 862702592.0000  PSNR: -53.06dB\n",
      "Epoch 63/400  Train Loss: 0.8149  Val Loss: 0.8161\n",
      "   → Sampled MSE: 874902400.0000  PSNR: -53.12dB\n",
      "Epoch 64/400  Train Loss: 0.8147  Val Loss: 0.8140\n",
      "   → Sampled MSE: 867941376.0000  PSNR: -53.09dB\n",
      "Epoch 65/400  Train Loss: 0.8144  Val Loss: 0.8154\n",
      "   → Sampled MSE: 868978944.0000  PSNR: -53.10dB\n",
      "Epoch 66/400  Train Loss: 0.8140  Val Loss: 0.8130\n",
      "   → Sampled MSE: 851145728.0000  PSNR: -53.01dB\n",
      "Epoch 67/400  Train Loss: 0.8132  Val Loss: 0.8141\n",
      "   → Sampled MSE: 864821504.0000  PSNR: -53.07dB\n",
      "Epoch 68/400  Train Loss: 0.8126  Val Loss: 0.8134\n",
      "   → Sampled MSE: 852267136.0000  PSNR: -53.01dB\n",
      "Epoch 69/400  Train Loss: 0.8123  Val Loss: 0.8122\n",
      "   → Sampled MSE: 862371072.0000  PSNR: -53.06dB\n",
      "Epoch 70/400  Train Loss: 0.8118  Val Loss: 0.8118\n",
      "   → Sampled MSE: 843384576.0000  PSNR: -52.97dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 71/400  Train Loss: 0.8119  Val Loss: 0.8110\n",
      "   → Sampled MSE: 857622720.0000  PSNR: -53.04dB\n",
      "Epoch 72/400  Train Loss: 0.8113  Val Loss: 0.8111\n",
      "   → Sampled MSE: 851302528.0000  PSNR: -53.01dB\n",
      "Epoch 73/400  Train Loss: 0.8107  Val Loss: 0.8107\n",
      "   → Sampled MSE: 850862720.0000  PSNR: -53.00dB\n",
      "Epoch 74/400  Train Loss: 0.8106  Val Loss: 0.8101\n",
      "   → Sampled MSE: 847496128.0000  PSNR: -52.99dB\n",
      "Epoch 75/400  Train Loss: 0.8094  Val Loss: 0.8107\n",
      "   → Sampled MSE: 843794432.0000  PSNR: -52.97dB\n",
      "Epoch 76/400  Train Loss: 0.8092  Val Loss: 0.8087\n",
      "   → Sampled MSE: 858439744.0000  PSNR: -53.04dB\n",
      "Epoch 77/400  Train Loss: 0.8091  Val Loss: 0.8081\n",
      "   → Sampled MSE: 850955136.0000  PSNR: -53.00dB\n",
      "Epoch 78/400  Train Loss: 0.8087  Val Loss: 0.8093\n",
      "   → Sampled MSE: 841853504.0000  PSNR: -52.96dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 79/400  Train Loss: 0.8082  Val Loss: 0.8091\n",
      "   → Sampled MSE: 845170560.0000  PSNR: -52.97dB\n",
      "Epoch 80/400  Train Loss: 0.8078  Val Loss: 0.8079\n",
      "   → Sampled MSE: 853549568.0000  PSNR: -53.02dB\n",
      "Epoch 81/400  Train Loss: 0.8075  Val Loss: 0.8070\n",
      "   → Sampled MSE: 844361856.0000  PSNR: -52.97dB\n",
      "Epoch 82/400  Train Loss: 0.8072  Val Loss: 0.8069\n",
      "   → Sampled MSE: 833442240.0000  PSNR: -52.91dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 83/400  Train Loss: 0.8069  Val Loss: 0.8068\n",
      "   → Sampled MSE: 838572544.0000  PSNR: -52.94dB\n",
      "Epoch 84/400  Train Loss: 0.8066  Val Loss: 0.8057\n",
      "   → Sampled MSE: 843457216.0000  PSNR: -52.97dB\n",
      "Epoch 85/400  Train Loss: 0.8059  Val Loss: 0.8049\n",
      "   → Sampled MSE: 846333824.0000  PSNR: -52.98dB\n",
      "Epoch 86/400  Train Loss: 0.8058  Val Loss: 0.8058\n",
      "   → Sampled MSE: 840413248.0000  PSNR: -52.95dB\n",
      "Epoch 87/400  Train Loss: 0.8049  Val Loss: 0.8077\n",
      "   → Sampled MSE: 844435712.0000  PSNR: -52.97dB\n",
      "Epoch 88/400  Train Loss: 0.8046  Val Loss: 0.8042\n",
      "   → Sampled MSE: 840913664.0000  PSNR: -52.95dB\n",
      "Epoch 89/400  Train Loss: 0.8043  Val Loss: 0.8053\n",
      "   → Sampled MSE: 834035392.0000  PSNR: -52.92dB\n",
      "Epoch 90/400  Train Loss: 0.8040  Val Loss: 0.8043\n",
      "   → Sampled MSE: 829543296.0000  PSNR: -52.89dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 91/400  Train Loss: 0.8040  Val Loss: 0.8038\n",
      "   → Sampled MSE: 837554560.0000  PSNR: -52.94dB\n",
      "Epoch 92/400  Train Loss: 0.8035  Val Loss: 0.8047\n",
      "   → Sampled MSE: 836306432.0000  PSNR: -52.93dB\n",
      "Epoch 93/400  Train Loss: 0.8033  Val Loss: 0.8027\n",
      "   → Sampled MSE: 837021056.0000  PSNR: -52.93dB\n",
      "Epoch 94/400  Train Loss: 0.8027  Val Loss: 0.8044\n",
      "   → Sampled MSE: 832357888.0000  PSNR: -52.91dB\n",
      "Epoch 95/400  Train Loss: 0.8022  Val Loss: 0.8028\n",
      "   → Sampled MSE: 830950912.0000  PSNR: -52.90dB\n",
      "Epoch 96/400  Train Loss: 0.8018  Val Loss: 0.8013\n",
      "   → Sampled MSE: 829054272.0000  PSNR: -52.89dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 97/400  Train Loss: 0.8017  Val Loss: 0.8008\n",
      "   → Sampled MSE: 837150720.0000  PSNR: -52.93dB\n",
      "Epoch 98/400  Train Loss: 0.8008  Val Loss: 0.8003\n",
      "   → Sampled MSE: 833726464.0000  PSNR: -52.92dB\n",
      "Epoch 99/400  Train Loss: 0.8005  Val Loss: 0.7995\n",
      "   → Sampled MSE: 832591360.0000  PSNR: -52.91dB\n",
      "Epoch 100/400  Train Loss: 0.7998  Val Loss: 0.7993\n",
      "   → Sampled MSE: 824489344.0000  PSNR: -52.87dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 101/400  Train Loss: 0.8000  Val Loss: 0.7999\n",
      "   → Sampled MSE: 828185536.0000  PSNR: -52.89dB\n",
      "Epoch 102/400  Train Loss: 0.7999  Val Loss: 0.7997\n",
      "   → Sampled MSE: 826392064.0000  PSNR: -52.88dB\n",
      "Epoch 103/400  Train Loss: 0.7993  Val Loss: 0.7986\n",
      "   → Sampled MSE: 832005760.0000  PSNR: -52.91dB\n",
      "Epoch 104/400  Train Loss: 0.7994  Val Loss: 0.7981\n",
      "   → Sampled MSE: 818573952.0000  PSNR: -52.84dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 105/400  Train Loss: 0.7987  Val Loss: 0.8009\n",
      "   → Sampled MSE: 820577216.0000  PSNR: -52.85dB\n",
      "Epoch 106/400  Train Loss: 0.7986  Val Loss: 0.7974\n",
      "   → Sampled MSE: 820196480.0000  PSNR: -52.84dB\n",
      "Epoch 107/400  Train Loss: 0.7983  Val Loss: 0.7977\n",
      "   → Sampled MSE: 830089088.0000  PSNR: -52.90dB\n",
      "Epoch 108/400  Train Loss: 0.7983  Val Loss: 0.7976\n",
      "   → Sampled MSE: 816348992.0000  PSNR: -52.82dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 109/400  Train Loss: 0.7975  Val Loss: 0.7978\n",
      "   → Sampled MSE: 822206080.0000  PSNR: -52.85dB\n",
      "Epoch 110/400  Train Loss: 0.7973  Val Loss: 0.7975\n",
      "   → Sampled MSE: 817778624.0000  PSNR: -52.83dB\n",
      "Epoch 111/400  Train Loss: 0.7964  Val Loss: 0.7956\n",
      "   → Sampled MSE: 818181888.0000  PSNR: -52.83dB\n",
      "Epoch 112/400  Train Loss: 0.7963  Val Loss: 0.7973\n",
      "   → Sampled MSE: 819489216.0000  PSNR: -52.84dB\n",
      "Epoch 113/400  Train Loss: 0.7964  Val Loss: 0.7949\n",
      "   → Sampled MSE: 818772224.0000  PSNR: -52.84dB\n",
      "Epoch 114/400  Train Loss: 0.7956  Val Loss: 0.7958\n",
      "   → Sampled MSE: 821854720.0000  PSNR: -52.85dB\n",
      "Epoch 115/400  Train Loss: 0.7955  Val Loss: 0.7950\n",
      "   → Sampled MSE: 814511488.0000  PSNR: -52.81dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 116/400  Train Loss: 0.7951  Val Loss: 0.7951\n",
      "   → Sampled MSE: 816353024.0000  PSNR: -52.82dB\n",
      "Epoch 117/400  Train Loss: 0.7950  Val Loss: 0.7936\n",
      "   → Sampled MSE: 814982912.0000  PSNR: -52.82dB\n",
      "Epoch 118/400  Train Loss: 0.7947  Val Loss: 0.7941\n",
      "   → Sampled MSE: 817761152.0000  PSNR: -52.83dB\n",
      "Epoch 119/400  Train Loss: 0.7945  Val Loss: 0.7960\n",
      "   → Sampled MSE: 804843648.0000  PSNR: -52.76dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 120/400  Train Loss: 0.7945  Val Loss: 0.7955\n",
      "   → Sampled MSE: 830767680.0000  PSNR: -52.90dB\n",
      "Epoch 121/400  Train Loss: 0.7939  Val Loss: 0.7939\n",
      "   → Sampled MSE: 819640192.0000  PSNR: -52.84dB\n",
      "Epoch 122/400  Train Loss: 0.7934  Val Loss: 0.7930\n",
      "   → Sampled MSE: 808226304.0000  PSNR: -52.78dB\n",
      "Epoch 123/400  Train Loss: 0.7928  Val Loss: 0.7939\n",
      "   → Sampled MSE: 803505408.0000  PSNR: -52.75dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 124/400  Train Loss: 0.7931  Val Loss: 0.7931\n",
      "   → Sampled MSE: 806733696.0000  PSNR: -52.77dB\n",
      "Epoch 125/400  Train Loss: 0.7924  Val Loss: 0.7920\n",
      "   → Sampled MSE: 804148224.0000  PSNR: -52.76dB\n",
      "Epoch 126/400  Train Loss: 0.7923  Val Loss: 0.7921\n",
      "   → Sampled MSE: 817408512.0000  PSNR: -52.83dB\n",
      "Epoch 127/400  Train Loss: 0.7923  Val Loss: 0.7933\n",
      "   → Sampled MSE: 809598208.0000  PSNR: -52.79dB\n",
      "Epoch 128/400  Train Loss: 0.7923  Val Loss: 0.7910\n",
      "   → Sampled MSE: 806984704.0000  PSNR: -52.77dB\n",
      "Epoch 129/400  Train Loss: 0.7911  Val Loss: 0.7906\n",
      "   → Sampled MSE: 803372800.0000  PSNR: -52.75dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 130/400  Train Loss: 0.7915  Val Loss: 0.7907\n",
      "   → Sampled MSE: 805337984.0000  PSNR: -52.76dB\n",
      "Epoch 131/400  Train Loss: 0.7907  Val Loss: 0.7907\n",
      "   → Sampled MSE: 802007168.0000  PSNR: -52.75dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 132/400  Train Loss: 0.7910  Val Loss: 0.7897\n",
      "   → Sampled MSE: 807077504.0000  PSNR: -52.77dB\n",
      "Epoch 133/400  Train Loss: 0.7904  Val Loss: 0.7911\n",
      "   → Sampled MSE: 810656000.0000  PSNR: -52.79dB\n",
      "Epoch 134/400  Train Loss: 0.7904  Val Loss: 0.7902\n",
      "   → Sampled MSE: 806599808.0000  PSNR: -52.77dB\n",
      "Epoch 135/400  Train Loss: 0.7897  Val Loss: 0.7895\n",
      "   → Sampled MSE: 807219712.0000  PSNR: -52.77dB\n",
      "Epoch 136/400  Train Loss: 0.7899  Val Loss: 0.7886\n",
      "   → Sampled MSE: 788573632.0000  PSNR: -52.67dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 137/400  Train Loss: 0.7898  Val Loss: 0.7890\n",
      "   → Sampled MSE: 805543616.0000  PSNR: -52.77dB\n",
      "Epoch 138/400  Train Loss: 0.7893  Val Loss: 0.7888\n",
      "   → Sampled MSE: 806953856.0000  PSNR: -52.77dB\n",
      "Epoch 139/400  Train Loss: 0.7891  Val Loss: 0.7898\n",
      "   → Sampled MSE: 799215104.0000  PSNR: -52.73dB\n",
      "Epoch 140/400  Train Loss: 0.7891  Val Loss: 0.7886\n",
      "   → Sampled MSE: 808147328.0000  PSNR: -52.78dB\n",
      "Epoch 141/400  Train Loss: 0.7890  Val Loss: 0.7881\n",
      "   → Sampled MSE: 804366528.0000  PSNR: -52.76dB\n",
      "Epoch 142/400  Train Loss: 0.7884  Val Loss: 0.7883\n",
      "   → Sampled MSE: 799954560.0000  PSNR: -52.74dB\n",
      "Epoch 143/400  Train Loss: 0.7880  Val Loss: 0.7878\n",
      "   → Sampled MSE: 814976000.0000  PSNR: -52.82dB\n",
      "Epoch 144/400  Train Loss: 0.7880  Val Loss: 0.7876\n",
      "   → Sampled MSE: 799274880.0000  PSNR: -52.73dB\n",
      "Epoch 145/400  Train Loss: 0.7882  Val Loss: 0.7885\n",
      "   → Sampled MSE: 805727296.0000  PSNR: -52.77dB\n",
      "Epoch 146/400  Train Loss: 0.7878  Val Loss: 0.7890\n",
      "   → Sampled MSE: 805563008.0000  PSNR: -52.77dB\n",
      "Epoch 147/400  Train Loss: 0.7876  Val Loss: 0.7891\n",
      "   → Sampled MSE: 807395776.0000  PSNR: -52.78dB\n",
      "Epoch 148/400  Train Loss: 0.7875  Val Loss: 0.7874\n",
      "   → Sampled MSE: 806003712.0000  PSNR: -52.77dB\n",
      "Epoch 149/400  Train Loss: 0.7872  Val Loss: 0.7870\n",
      "   → Sampled MSE: 796865280.0000  PSNR: -52.72dB\n",
      "Epoch 150/400  Train Loss: 0.7873  Val Loss: 0.7867\n",
      "   → Sampled MSE: 794209280.0000  PSNR: -52.70dB\n",
      "Epoch 151/400  Train Loss: 0.7862  Val Loss: 0.7865\n",
      "   → Sampled MSE: 801702016.0000  PSNR: -52.75dB\n",
      "Epoch 152/400  Train Loss: 0.7860  Val Loss: 0.7861\n",
      "   → Sampled MSE: 800646656.0000  PSNR: -52.74dB\n",
      "Epoch 153/400  Train Loss: 0.7856  Val Loss: 0.7853\n",
      "   → Sampled MSE: 789629056.0000  PSNR: -52.68dB\n",
      "Epoch 154/400  Train Loss: 0.7857  Val Loss: 0.7854\n",
      "   → Sampled MSE: 792555200.0000  PSNR: -52.70dB\n",
      "Epoch 155/400  Train Loss: 0.7861  Val Loss: 0.7866\n",
      "   → Sampled MSE: 795929856.0000  PSNR: -52.71dB\n",
      "Epoch 156/400  Train Loss: 0.7854  Val Loss: 0.7844\n",
      "   → Sampled MSE: 788039040.0000  PSNR: -52.67dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 157/400  Train Loss: 0.7852  Val Loss: 0.7863\n",
      "   → Sampled MSE: 795144832.0000  PSNR: -52.71dB\n",
      "Epoch 158/400  Train Loss: 0.7846  Val Loss: 0.7842\n",
      "   → Sampled MSE: 791723904.0000  PSNR: -52.69dB\n",
      "Epoch 159/400  Train Loss: 0.7844  Val Loss: 0.7837\n",
      "   → Sampled MSE: 794727168.0000  PSNR: -52.71dB\n",
      "Epoch 160/400  Train Loss: 0.7843  Val Loss: 0.7835\n",
      "   → Sampled MSE: 791793280.0000  PSNR: -52.69dB\n",
      "Epoch 161/400  Train Loss: 0.7843  Val Loss: 0.7838\n",
      "   → Sampled MSE: 787683840.0000  PSNR: -52.67dB\n",
      "   → Saved new best‑MSE model\n",
      "Epoch 162/400  Train Loss: 0.7843  Val Loss: 0.7839\n",
      "   → Sampled MSE: 788047936.0000  PSNR: -52.67dB\n",
      "Epoch 163/400  Train Loss: 0.7839  Val Loss: 0.7841\n",
      "   → Sampled MSE: 790530368.0000  PSNR: -52.68dB\n",
      "Epoch 164/400  Train Loss: 0.7836  Val Loss: 0.7838\n",
      "   → Sampled MSE: 787006720.0000  PSNR: -52.66dB\n",
      "   → Saved new best‑MSE model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# —–––––––––––––––––––––––––––––––––––––––––––––––––––––––––\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# training loop\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# —–––––––––––––––––––––––––––––––––––––––––––––––––––––––––\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     val_loss, gen_mse, gen_psnr \u001b[38;5;241m=\u001b[39m validate(diffusion, val_loader, device)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/utils/Dtrainer.py:32\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(diffusion, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 32\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader = norm_train_loader\n",
    "val_loader   = norm_val_loader\n",
    "\n",
    "model        = DualBranchConditionalUNet(time_emb_dim=config.time_emb_dim).to(device)\n",
    "diffusion    = ConditionalDiffusion(model, scheduler_type=config.scheduler_type,\n",
    "                                   T=config.noise_steps,\n",
    "                                   beta_start=config.beta_start,\n",
    "                                   beta_end=config.beta_end).to(device)\n",
    "optimizer    = torch.optim.Adam(diffusion.parameters(), lr=config.learning_rate)\n",
    "scheduler    = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                   optimizer,\n",
    "                   mode='min', factor=0.5,\n",
    "                   patience=10, threshold=1e-4,\n",
    "                   cooldown=15, min_lr=1e-6,\n",
    "                   verbose=True)\n",
    "\n",
    "best_mse_loss = float('inf')\n",
    "num_epochs    = config.num_epochs\n",
    "\n",
    "# —–––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "# training loop\n",
    "# —–––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = train_one_epoch(diffusion, train_loader, optimizer, device)\n",
    "    val_loss, gen_mse, gen_psnr = validate(diffusion, val_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs}  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "    if gen_mse is not None:\n",
    "        print(f\"   → Sampled MSE: {gen_mse:.4f}  PSNR: {gen_psnr:.2f}dB\")\n",
    "\n",
    "    # Scheduler step on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save best MSE\n",
    "    if gen_mse is not None and gen_mse < best_mse_loss:\n",
    "        best_mse_loss = gen_mse\n",
    "        torch.save(diffusion.state_dict(), f\"{run_name}_best_mse.pth\")\n",
    "        print(\"   → Saved new best‑MSE model\")\n",
    "\n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"sample_mse\": gen_mse,\n",
    "        \"sample_psnr\": gen_psnr,\n",
    "        \"lr\": optimizer.param_groups[0]['lr']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hawk/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 4, 3, 3], expected input[16, 0, 64, 64] to have 4 channels, but got 0 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m best_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[0;32m---> 28\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mDB_train_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_diffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     val_loss, mse, psnr \u001b[38;5;241m=\u001b[39m DB_validate(cond_diffusion, val_loader, device)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] train=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m           \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | MSE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m PSNR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpsnr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/utils/trainer.py:113\u001b[0m, in \u001b[0;36mDB_train_one_epoch\u001b[0;34m(diffusion, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m    111\u001b[0m B \u001b[38;5;241m=\u001b[39m x_noisy\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    112\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, diffusion\u001b[38;5;241m.\u001b[39mT, (B,), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 113\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscnr_dBs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    116\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/models/diffusion.py:37\u001b[0m, in \u001b[0;36mConditionalDiffusion.p_losses\u001b[0;34m(self, x0, t, cond, scnr)\u001b[0m\n\u001b[1;32m     35\u001b[0m t_norm \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     36\u001b[0m model_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_noisy, cond], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscnr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#model_input, t_norm)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/models/unet.py:397\u001b[0m, in \u001b[0;36mDualBranchUNet.forward\u001b[0;34m(self, x, cond, scnr, t)\u001b[0m\n\u001b[1;32m    394\u001b[0m iq2_skip, iq2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miq_down1(iq1)           \u001b[38;5;66;03m# skip=(B,128,H/2,W/2), iq2=(B,128,H/2,W/2)\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# ——— RD branch encoder ———\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m rd1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrd_inc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m                  \u001b[38;5;66;03m# -> (B,  64, H, W)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m rd2_skip, rd2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrd_down1(rd1)           \u001b[38;5;66;03m# skip=(B,128,H/2,W/2), rd2=(B,128,H/2,W/2)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# ——— cross‑attention at first scale ———\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/models/unet.py:219\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 4, 3, 3], expected input[16, 0, 64, 64] to have 4 channels, but got 0 channels instead"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run rei4tyrh was previously created and deleted; try a new run name (<Response [409]>)\n",
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 41, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 2188, in upsert_run\n",
      "    response = self.gql(\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 312, in gql\n",
      "    ret = self._retry_gql(\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/lib/retry.py\", line 131, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py\", line 340, in execute\n",
      "    return self.client.execute(*args, **kwargs)  # type: ignore\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/lib/gql_request.py\", line 59, in execute\n",
      "    request.raise_for_status()\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/requests/models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://api.wandb.ai/graphql\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 48, in run\n",
      "    self._run()\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 92, in _run\n",
      "    self._debounce()\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 333, in _debounce\n",
      "    self._sm.debounce()\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 537, in debounce\n",
      "    self._maybe_update_config(always=final)\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 514, in _maybe_update_config\n",
      "    self._debounce_config()\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 543, in _debounce_config\n",
      "    self._api.upsert_run(\n",
      "  File \"/home/hawk/.local/lib/python3.10/site-packages/wandb/apis/normalize.py\", line 51, in wrapper\n",
      "    raise CommError(message, error)\n",
      "wandb.errors.CommError: run rei4tyrh was previously created and deleted; try a new run name (Error 409: Conflict)\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n"
     ]
    }
   ],
   "source": [
    "train_loader = norm_train_loader\n",
    "val_loader = norm_val_loader\n",
    "cond_unet = ConditionalUNet(in_channels=4, out_channels=2, time_emb_dim=config.time_emb_dim).to(device)\n",
    "\n",
    "cond_diffusion = ConditionalDiffusion(model=cond_unet, scheduler_type=config.scheduler_type, T=config.noise_steps, \n",
    "    beta_start=config.beta_start, beta_end=config.beta_end).to(device)\n",
    "optimizer = torch.optim.Adam(cond_diffusion.parameters(), config.learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, threshold=1e-4, cooldown=15, min_lr=1e-6, verbose=True)\n",
    "num_epochs = config.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400: Train Loss = 0.0567 | Val Loss = 0.0302\n",
      "   [Generation Metrics] MSE: 1268.0046 | PSNR: 5.65 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 2/400: Train Loss = 0.0262 | Val Loss = 0.0233\n",
      "   [Generation Metrics] MSE: 57.2247 | PSNR: 19.11 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 3/400: Train Loss = 0.0214 | Val Loss = 0.0196\n",
      "   [Generation Metrics] MSE: 442.7359 | PSNR: 10.22 dB\n",
      "Epoch 4/400: Train Loss = 0.0188 | Val Loss = 0.0169\n",
      "   [Generation Metrics] MSE: 68197.4062 | PSNR: -11.66 dB\n",
      "Epoch 5/400: Train Loss = 0.0163 | Val Loss = 0.0146\n",
      "   [Generation Metrics] MSE: 7343.7451 | PSNR: -1.98 dB\n",
      "Epoch 6/400: Train Loss = 0.0154 | Val Loss = 0.0135\n",
      "   [Generation Metrics] MSE: 23469.3086 | PSNR: -7.02 dB\n",
      "Epoch 7/400: Train Loss = 0.0146 | Val Loss = 0.0131\n",
      "   [Generation Metrics] MSE: 7.6419 | PSNR: 27.85 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 8/400: Train Loss = 0.0136 | Val Loss = 0.0129\n",
      "   [Generation Metrics] MSE: 31431.8379 | PSNR: -8.29 dB\n",
      "Epoch 9/400: Train Loss = 0.0129 | Val Loss = 0.0128\n",
      "   [Generation Metrics] MSE: 17541.3926 | PSNR: -5.76 dB\n",
      "Epoch 10/400: Train Loss = 0.0125 | Val Loss = 0.0118\n",
      "   [Generation Metrics] MSE: 816.0147 | PSNR: 7.56 dB\n",
      "Epoch 11/400: Train Loss = 0.0118 | Val Loss = 0.0119\n",
      "   [Generation Metrics] MSE: 258.4392 | PSNR: 12.56 dB\n",
      "Epoch 12/400: Train Loss = 0.0118 | Val Loss = 0.0116\n",
      "   [Generation Metrics] MSE: 44.7140 | PSNR: 20.18 dB\n",
      "Epoch 13/400: Train Loss = 0.0113 | Val Loss = 0.0107\n",
      "   [Generation Metrics] MSE: 0.5065 | PSNR: 39.63 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 14/400: Train Loss = 0.0107 | Val Loss = 0.0119\n",
      "   [Generation Metrics] MSE: 479.9450 | PSNR: 9.87 dB\n",
      "Epoch 15/400: Train Loss = 0.0106 | Val Loss = 0.0107\n",
      "   [Generation Metrics] MSE: 0.3061 | PSNR: 41.82 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 16/400: Train Loss = 0.0102 | Val Loss = 0.0099\n",
      "   [Generation Metrics] MSE: 23.0250 | PSNR: 23.06 dB\n",
      "Epoch 17/400: Train Loss = 0.0102 | Val Loss = 0.0099\n",
      "   [Generation Metrics] MSE: 0.2984 | PSNR: 41.93 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 18/400: Train Loss = 0.0096 | Val Loss = 0.0095\n",
      "   [Generation Metrics] MSE: 165.5441 | PSNR: 14.49 dB\n",
      "Epoch 19/400: Train Loss = 0.0096 | Val Loss = 0.0098\n",
      "   [Generation Metrics] MSE: 0.2447 | PSNR: 42.80 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 20/400: Train Loss = 0.0095 | Val Loss = 0.0095\n",
      "   [Generation Metrics] MSE: 0.1483 | PSNR: 44.97 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 21/400: Train Loss = 0.0091 | Val Loss = 0.0088\n",
      "   [Generation Metrics] MSE: 0.7954 | PSNR: 37.68 dB\n",
      "Epoch 22/400: Train Loss = 0.0089 | Val Loss = 0.0086\n",
      "   [Generation Metrics] MSE: 0.1532 | PSNR: 44.83 dB\n",
      "Epoch 23/400: Train Loss = 0.0088 | Val Loss = 0.0089\n",
      "   [Generation Metrics] MSE: 0.1161 | PSNR: 46.03 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 24/400: Train Loss = 0.0086 | Val Loss = 0.0076\n",
      "   [Generation Metrics] MSE: 0.1111 | PSNR: 46.22 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 25/400: Train Loss = 0.0085 | Val Loss = 0.0081\n",
      "   [Generation Metrics] MSE: 0.1015 | PSNR: 46.62 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 26/400: Train Loss = 0.0086 | Val Loss = 0.0080\n",
      "   [Generation Metrics] MSE: 0.1963 | PSNR: 43.75 dB\n",
      "Epoch 27/400: Train Loss = 0.0083 | Val Loss = 0.0080\n",
      "   [Generation Metrics] MSE: 0.1265 | PSNR: 45.66 dB\n",
      "Epoch 28/400: Train Loss = 0.0084 | Val Loss = 0.0081\n",
      "   [Generation Metrics] MSE: 0.1265 | PSNR: 45.66 dB\n",
      "Epoch 29/400: Train Loss = 0.0081 | Val Loss = 0.0080\n",
      "   [Generation Metrics] MSE: 0.1157 | PSNR: 46.05 dB\n",
      "Epoch 30/400: Train Loss = 0.0082 | Val Loss = 0.0076\n",
      "   [Generation Metrics] MSE: 0.1214 | PSNR: 45.84 dB\n",
      "Epoch 31/400: Train Loss = 0.0080 | Val Loss = 0.0080\n",
      "   [Generation Metrics] MSE: 4.7532 | PSNR: 29.91 dB\n",
      "Epoch 32/400: Train Loss = 0.0079 | Val Loss = 0.0075\n",
      "   [Generation Metrics] MSE: 0.1064 | PSNR: 46.41 dB\n",
      "Epoch 33/400: Train Loss = 0.0080 | Val Loss = 0.0079\n",
      "   [Generation Metrics] MSE: 0.1102 | PSNR: 46.26 dB\n",
      "Epoch 34/400: Train Loss = 0.0078 | Val Loss = 0.0072\n",
      "   [Generation Metrics] MSE: 0.0940 | PSNR: 46.95 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 35/400: Train Loss = 0.0080 | Val Loss = 0.0079\n",
      "   [Generation Metrics] MSE: 0.0850 | PSNR: 47.39 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 36/400: Train Loss = 0.0078 | Val Loss = 0.0077\n",
      "   [Generation Metrics] MSE: 0.0657 | PSNR: 48.50 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 37/400: Train Loss = 0.0076 | Val Loss = 0.0089\n",
      "   [Generation Metrics] MSE: 0.1293 | PSNR: 45.57 dB\n",
      "Epoch 38/400: Train Loss = 0.0078 | Val Loss = 0.0073\n",
      "   [Generation Metrics] MSE: 0.1170 | PSNR: 46.00 dB\n",
      "Epoch 39/400: Train Loss = 0.0075 | Val Loss = 0.0073\n",
      "   [Generation Metrics] MSE: 0.1126 | PSNR: 46.17 dB\n",
      "Epoch 40/400: Train Loss = 0.0074 | Val Loss = 0.0076\n",
      "   [Generation Metrics] MSE: 0.0917 | PSNR: 47.06 dB\n",
      "Epoch 41/400: Train Loss = 0.0073 | Val Loss = 0.0075\n",
      "   [Generation Metrics] MSE: 0.1185 | PSNR: 45.94 dB\n",
      "Epoch 42/400: Train Loss = 0.0075 | Val Loss = 0.0066\n",
      "   [Generation Metrics] MSE: 0.0822 | PSNR: 47.53 dB\n",
      "Epoch 43/400: Train Loss = 0.0075 | Val Loss = 0.0070\n",
      "   [Generation Metrics] MSE: 0.0736 | PSNR: 48.01 dB\n",
      "Epoch 44/400: Train Loss = 0.0071 | Val Loss = 0.0076\n",
      "   [Generation Metrics] MSE: 0.0601 | PSNR: 48.89 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 45/400: Train Loss = 0.0071 | Val Loss = 0.0072\n",
      "   [Generation Metrics] MSE: 0.0734 | PSNR: 48.02 dB\n",
      "Epoch 46/400: Train Loss = 0.0070 | Val Loss = 0.0070\n",
      "   [Generation Metrics] MSE: 0.0849 | PSNR: 47.39 dB\n",
      "Epoch 47/400: Train Loss = 0.0072 | Val Loss = 0.0070\n",
      "   [Generation Metrics] MSE: 0.0767 | PSNR: 47.83 dB\n",
      "Epoch 48/400: Train Loss = 0.0070 | Val Loss = 0.0075\n",
      "   [Generation Metrics] MSE: 0.1178 | PSNR: 45.97 dB\n",
      "Epoch 49/400: Train Loss = 0.0071 | Val Loss = 0.0069\n",
      "   [Generation Metrics] MSE: 0.1190 | PSNR: 45.92 dB\n",
      "Epoch 50/400: Train Loss = 0.0070 | Val Loss = 0.0068\n",
      "   [Generation Metrics] MSE: 0.2338 | PSNR: 42.99 dB\n",
      "Epoch 51/400: Train Loss = 0.0069 | Val Loss = 0.0068\n",
      "   [Generation Metrics] MSE: 0.0936 | PSNR: 46.97 dB\n",
      "Epoch 52/400: Train Loss = 0.0070 | Val Loss = 0.0072\n",
      "   [Generation Metrics] MSE: 0.0841 | PSNR: 47.43 dB\n",
      "Epoch 53/400: Train Loss = 0.0068 | Val Loss = 0.0067\n",
      "   [Generation Metrics] MSE: 0.0688 | PSNR: 48.30 dB\n",
      "Epoch 54/400: Train Loss = 0.0065 | Val Loss = 0.0063\n",
      "   [Generation Metrics] MSE: 0.0678 | PSNR: 48.37 dB\n",
      "Epoch 55/400: Train Loss = 0.0064 | Val Loss = 0.0064\n",
      "   [Generation Metrics] MSE: 0.0643 | PSNR: 48.60 dB\n",
      "Epoch 56/400: Train Loss = 0.0063 | Val Loss = 0.0069\n",
      "   [Generation Metrics] MSE: 0.0777 | PSNR: 47.78 dB\n",
      "Epoch 57/400: Train Loss = 0.0065 | Val Loss = 0.0067\n",
      "   [Generation Metrics] MSE: 0.0654 | PSNR: 48.52 dB\n",
      "Epoch 58/400: Train Loss = 0.0063 | Val Loss = 0.0065\n",
      "   [Generation Metrics] MSE: 0.0858 | PSNR: 47.35 dB\n",
      "Epoch 59/400: Train Loss = 0.0063 | Val Loss = 0.0064\n",
      "   [Generation Metrics] MSE: 0.0842 | PSNR: 47.43 dB\n",
      "Epoch 60/400: Train Loss = 0.0062 | Val Loss = 0.0065\n",
      "   [Generation Metrics] MSE: 0.0672 | PSNR: 48.41 dB\n",
      "Epoch 61/400: Train Loss = 0.0063 | Val Loss = 0.0064\n",
      "   [Generation Metrics] MSE: 0.0535 | PSNR: 49.39 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 62/400: Train Loss = 0.0063 | Val Loss = 0.0065\n",
      "   [Generation Metrics] MSE: 0.0583 | PSNR: 49.02 dB\n",
      "Epoch 63/400: Train Loss = 0.0063 | Val Loss = 0.0061\n",
      "   [Generation Metrics] MSE: 0.0974 | PSNR: 46.80 dB\n",
      "Epoch 64/400: Train Loss = 0.0060 | Val Loss = 0.0067\n",
      "   [Generation Metrics] MSE: 0.0743 | PSNR: 47.97 dB\n",
      "Epoch 65/400: Train Loss = 0.0062 | Val Loss = 0.0061\n",
      "   [Generation Metrics] MSE: 0.0848 | PSNR: 47.40 dB\n",
      "Epoch 66/400: Train Loss = 0.0061 | Val Loss = 0.0065\n",
      "   [Generation Metrics] MSE: 0.0610 | PSNR: 48.82 dB\n",
      "Epoch 67/400: Train Loss = 0.0062 | Val Loss = 0.0062\n",
      "   [Generation Metrics] MSE: 0.1015 | PSNR: 46.61 dB\n",
      "Epoch 68/400: Train Loss = 0.0061 | Val Loss = 0.0063\n",
      "   [Generation Metrics] MSE: 0.0819 | PSNR: 47.55 dB\n",
      "Epoch 69/400: Train Loss = 0.0062 | Val Loss = 0.0065\n",
      "   [Generation Metrics] MSE: 0.0617 | PSNR: 48.78 dB\n",
      "Epoch 70/400: Train Loss = 0.0062 | Val Loss = 0.0067\n",
      "   [Generation Metrics] MSE: 0.0693 | PSNR: 48.27 dB\n",
      "Epoch 71/400: Train Loss = 0.0061 | Val Loss = 0.0063\n",
      "   [Generation Metrics] MSE: 0.0985 | PSNR: 46.75 dB\n",
      "Epoch 72/400: Train Loss = 0.0060 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0889 | PSNR: 47.19 dB\n",
      "Epoch 73/400: Train Loss = 0.0060 | Val Loss = 0.0061\n",
      "   [Generation Metrics] MSE: 0.0795 | PSNR: 47.68 dB\n",
      "Epoch 74/400: Train Loss = 0.0061 | Val Loss = 0.0062\n",
      "   [Generation Metrics] MSE: 0.0803 | PSNR: 47.64 dB\n",
      "Epoch 75/400: Train Loss = 0.0061 | Val Loss = 0.0060\n",
      "   [Generation Metrics] MSE: 0.0607 | PSNR: 48.85 dB\n",
      "Epoch 76/400: Train Loss = 0.0059 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0779 | PSNR: 47.76 dB\n",
      "Epoch 77/400: Train Loss = 0.0061 | Val Loss = 0.0061\n",
      "   [Generation Metrics] MSE: 0.1064 | PSNR: 46.41 dB\n",
      "Epoch 78/400: Train Loss = 0.0061 | Val Loss = 0.0060\n",
      "   [Generation Metrics] MSE: 0.0514 | PSNR: 49.57 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 79/400: Train Loss = 0.0061 | Val Loss = 0.0064\n",
      "   [Generation Metrics] MSE: 0.0549 | PSNR: 49.28 dB\n",
      "Epoch 80/400: Train Loss = 0.0061 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0842 | PSNR: 47.43 dB\n",
      "Epoch 81/400: Train Loss = 0.0060 | Val Loss = 0.0061\n",
      "   [Generation Metrics] MSE: 0.0567 | PSNR: 49.14 dB\n",
      "Epoch 82/400: Train Loss = 0.0060 | Val Loss = 0.0056\n",
      "   [Generation Metrics] MSE: 0.0595 | PSNR: 48.93 dB\n",
      "Epoch 83/400: Train Loss = 0.0059 | Val Loss = 0.0060\n",
      "   [Generation Metrics] MSE: 0.0616 | PSNR: 48.78 dB\n",
      "Epoch 84/400: Train Loss = 0.0059 | Val Loss = 0.0059\n",
      "   [Generation Metrics] MSE: 0.0535 | PSNR: 49.40 dB\n",
      "Epoch 85/400: Train Loss = 0.0059 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0616 | PSNR: 48.78 dB\n",
      "Epoch 86/400: Train Loss = 0.0059 | Val Loss = 0.0065\n",
      "   [Generation Metrics] MSE: 0.0565 | PSNR: 49.16 dB\n",
      "Epoch 87/400: Train Loss = 0.0059 | Val Loss = 0.0055\n",
      "   [Generation Metrics] MSE: 0.0522 | PSNR: 49.50 dB\n",
      "Epoch 88/400: Train Loss = 0.0059 | Val Loss = 0.0059\n",
      "   [Generation Metrics] MSE: 0.0524 | PSNR: 49.49 dB\n",
      "Epoch 89/400: Train Loss = 0.0059 | Val Loss = 0.0062\n",
      "   [Generation Metrics] MSE: 0.0677 | PSNR: 48.38 dB\n",
      "Epoch 90/400: Train Loss = 0.0058 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0557 | PSNR: 49.22 dB\n",
      "Epoch 91/400: Train Loss = 0.0057 | Val Loss = 0.0061\n",
      "   [Generation Metrics] MSE: 0.0532 | PSNR: 49.42 dB\n",
      "Epoch 92/400: Train Loss = 0.0058 | Val Loss = 0.0060\n",
      "   [Generation Metrics] MSE: 0.0585 | PSNR: 49.01 dB\n",
      "Epoch 93/400: Train Loss = 0.0058 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0546 | PSNR: 49.31 dB\n",
      "Epoch 94/400: Train Loss = 0.0059 | Val Loss = 0.0056\n",
      "   [Generation Metrics] MSE: 0.0654 | PSNR: 48.53 dB\n",
      "Epoch 95/400: Train Loss = 0.0057 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0634 | PSNR: 48.66 dB\n",
      "Epoch 96/400: Train Loss = 0.0057 | Val Loss = 0.0059\n",
      "   [Generation Metrics] MSE: 0.0739 | PSNR: 48.00 dB\n",
      "Epoch 97/400: Train Loss = 0.0057 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0629 | PSNR: 48.70 dB\n",
      "Epoch 98/400: Train Loss = 0.0058 | Val Loss = 0.0053\n",
      "   [Generation Metrics] MSE: 0.0692 | PSNR: 48.28 dB\n",
      "Epoch 99/400: Train Loss = 0.0057 | Val Loss = 0.0055\n",
      "   [Generation Metrics] MSE: 0.0629 | PSNR: 48.69 dB\n",
      "Epoch 100/400: Train Loss = 0.0056 | Val Loss = 0.0056\n",
      "   [Generation Metrics] MSE: 0.0578 | PSNR: 49.06 dB\n",
      "Epoch 101/400: Train Loss = 0.0056 | Val Loss = 0.0057\n",
      "   [Generation Metrics] MSE: 0.0749 | PSNR: 47.94 dB\n",
      "Epoch 102/400: Train Loss = 0.0055 | Val Loss = 0.0060\n",
      "   [Generation Metrics] MSE: 0.0750 | PSNR: 47.93 dB\n",
      "Epoch 103/400: Train Loss = 0.0057 | Val Loss = 0.0057\n",
      "   [Generation Metrics] MSE: 0.0566 | PSNR: 49.15 dB\n",
      "Epoch 104/400: Train Loss = 0.0057 | Val Loss = 0.0053\n",
      "   [Generation Metrics] MSE: 0.0947 | PSNR: 46.92 dB\n",
      "Epoch 105/400: Train Loss = 0.0056 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0558 | PSNR: 49.22 dB\n",
      "Epoch 106/400: Train Loss = 0.0056 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0806 | PSNR: 47.62 dB\n",
      "Epoch 107/400: Train Loss = 0.0057 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0681 | PSNR: 48.35 dB\n",
      "Epoch 108/400: Train Loss = 0.0057 | Val Loss = 0.0060\n",
      "   [Generation Metrics] MSE: 0.0717 | PSNR: 48.13 dB\n",
      "Epoch 109/400: Train Loss = 0.0056 | Val Loss = 0.0057\n",
      "   [Generation Metrics] MSE: 0.0492 | PSNR: 49.76 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 110/400: Train Loss = 0.0056 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0368 | PSNR: 51.03 dB\n",
      "   --> Best MSE model saved.\n",
      "Epoch 111/400: Train Loss = 0.0056 | Val Loss = 0.0057\n",
      "   [Generation Metrics] MSE: 0.0751 | PSNR: 47.92 dB\n",
      "Epoch 112/400: Train Loss = 0.0055 | Val Loss = 0.0056\n",
      "   [Generation Metrics] MSE: 0.0602 | PSNR: 48.88 dB\n",
      "Epoch 113/400: Train Loss = 0.0055 | Val Loss = 0.0053\n",
      "   [Generation Metrics] MSE: 0.0651 | PSNR: 48.55 dB\n",
      "Epoch 114/400: Train Loss = 0.0055 | Val Loss = 0.0056\n",
      "   [Generation Metrics] MSE: 0.0608 | PSNR: 48.85 dB\n",
      "Epoch 115/400: Train Loss = 0.0054 | Val Loss = 0.0053\n",
      "   [Generation Metrics] MSE: 0.0749 | PSNR: 47.94 dB\n",
      "Epoch 116/400: Train Loss = 0.0055 | Val Loss = 0.0058\n",
      "   [Generation Metrics] MSE: 0.0550 | PSNR: 49.28 dB\n",
      "Epoch 117/400: Train Loss = 0.0054 | Val Loss = 0.0050\n",
      "   [Generation Metrics] MSE: 0.1134 | PSNR: 46.14 dB\n",
      "Epoch 118/400: Train Loss = 0.0053 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0486 | PSNR: 49.81 dB\n",
      "Epoch 119/400: Train Loss = 0.0055 | Val Loss = 0.0053\n",
      "   [Generation Metrics] MSE: 0.0822 | PSNR: 47.53 dB\n",
      "Epoch 120/400: Train Loss = 0.0052 | Val Loss = 0.0054\n",
      "   [Generation Metrics] MSE: 0.0580 | PSNR: 49.05 dB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m rd_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#train_loss, e_mse_loss, e_rd_loss= train_one_epoch(cond_diffusion, train_loader, optimizer, device)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#val_loss, iq_val_loss, rd_val_loss, gen_mse, gen_psnr, rd_mse = validate(cond_diffusion, val_loader, device)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     train_loss\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_diffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     val_loss, gen_mse, gen_psnr \u001b[38;5;241m=\u001b[39m validate(cond_diffusion, val_loader, device)\n\u001b[1;32m     16\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m~/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/utils/trainer.py:37\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(diffusion, dataloader, optimizer, device, use_standard_loss, use_rd_loss)\u001b[0m\n\u001b[1;32m     35\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_mse_loss = float('inf')\n",
    "train_losses, val_losses, val_psnrs, val_mses = [], [], [], []\n",
    "e_mse_loss = None\n",
    "e_rd_loss = None\n",
    "iq_val_loss = None\n",
    "rd_val_loss = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #train_loss, e_mse_loss, e_rd_loss= train_one_epoch(cond_diffusion, train_loader, optimizer, device)\n",
    "    #val_loss, iq_val_loss, rd_val_loss, gen_mse, gen_psnr, rd_mse = validate(cond_diffusion, val_loader, device)\n",
    "\n",
    "    train_loss= train_one_epoch(cond_diffusion, train_loader, optimizer, device)\n",
    "    val_loss, gen_mse, gen_psnr = validate(cond_diffusion, val_loader, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if gen_psnr is not None:\n",
    "        val_psnrs.append(gen_psnr)\n",
    "    if gen_mse is not None:\n",
    "        val_mses.append(gen_mse)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.4f} | Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    if gen_mse is not None and gen_psnr is not None:\n",
    "        print(f\"   [Generation Metrics] MSE: {gen_mse:.4f} | PSNR: {gen_psnr:.2f} dB\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if gen_mse < best_mse_loss:\n",
    "        best_mse_loss = gen_mse\n",
    "        torch.save(cond_diffusion.state_dict(), f\"{run_name}.pth\")\n",
    "        print(\"   --> Best MSE model saved.\")\n",
    "\n",
    "    wandb.log({\n",
    "        \"total train loss\": train_loss,\n",
    "        \"total val loss\": val_loss,\n",
    "        \"MSE between denoised IQ and clean IQ\": gen_mse if gen_mse is not None else float('nan'),\n",
    "        \"generated IQ map PSNR\": gen_psnr,\n",
    "        \"learning rate\": optimizer.param_groups[0]['lr']  # Optional, log current LR\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path = \"/home/hawk/Desktop/Heavy Detector/Heavy-Clutter-Detection/finalDiffusion/comp1-reg_diff_snr10_cnr15.pth\"\n",
    "run_inference(cond_diffusion , norm_val_dataset, checkpoint_path, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
